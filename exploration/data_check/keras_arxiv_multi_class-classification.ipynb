{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pandas.HDFStore(\"arxiv_data/astroph_2016_preprocessed.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = store['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15842, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15842 entries, 0 to 15841\n",
      "Data columns (total 7 columns):\n",
      "title         15842 non-null object\n",
      "abstract      15842 non-null object\n",
      "categories    15842 non-null object\n",
      "created       15842 non-null datetime64[ns]\n",
      "id            15842 non-null object\n",
      "doi           14028 non-null object\n",
      "label         15842 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), object(5)\n",
      "memory usage: 990.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['abstract']\n",
    "labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "training_samples = 2000\n",
    "validation_samples = 10000\n",
    "max_words = 10000 # Top 10000 words\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30581 unique tokens\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(\"Found %s unique tokens\" % len(word_index))\n",
    "\n",
    "word_index_reverse = dict()\n",
    "for k, v in word_index.items():\n",
    "    word_index_reverse[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences=sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "indices = np.arange(texts.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "\n",
    "x_val = data[training_samples:training_samples+validation_samples]\n",
    "y_val = labels[training_samples:training_samples+validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name_dict = { 'astro-ph.GA' : 0,\n",
    "                     'astro-ph.SR' : 1,\n",
    "                     'astro-ph.IM' : 2,\n",
    "                     'astro-ph.EP' : 3,\n",
    "                     'astro-ph.HE' : 4,\n",
    "                     'astro-ph.CO' : 5\n",
    "                   }\n",
    "target_name = [k for k, v in target_name_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astro-ph.GA',\n",
       " 'astro-ph.SR',\n",
       " 'astro-ph.IM',\n",
       " 'astro-ph.EP',\n",
       " 'astro-ph.HE',\n",
       " 'astro-ph.CO']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_val_one_hot = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing GloVe file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "glove_dir = \"./glove.6B/\"\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 100 \n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embeddings_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,640,454\n",
      "Trainable params: 1,640,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embeddings_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.9951 - acc: 0.2250 - val_loss: 1.8363 - val_acc: 0.2029\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 0s 132us/step - loss: 1.5270 - acc: 0.4020 - val_loss: 1.7879 - val_acc: 0.2880\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 0s 126us/step - loss: 1.1424 - acc: 0.5615 - val_loss: 2.2668 - val_acc: 0.2151\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 0s 122us/step - loss: 0.7412 - acc: 0.7475 - val_loss: 1.9755 - val_acc: 0.2854\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 0s 120us/step - loss: 0.4185 - acc: 0.8940 - val_loss: 4.1792 - val_acc: 0.1984\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 0s 121us/step - loss: 0.2463 - acc: 0.9410 - val_loss: 2.6051 - val_acc: 0.3025\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 0s 126us/step - loss: 0.1390 - acc: 0.9695 - val_loss: 2.0238 - val_acc: 0.3454\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 0s 120us/step - loss: 0.1049 - acc: 0.9710 - val_loss: 1.9741 - val_acc: 0.3833\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 0s 124us/step - loss: 0.0728 - acc: 0.9810 - val_loss: 2.1903 - val_acc: 0.3828\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 0s 121us/step - loss: 0.0376 - acc: 0.9920 - val_loss: 2.2944 - val_acc: 0.3706\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data = (x_val, y_val_one_hot))\n",
    "model.save_weights('pre_trained_glove_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "sampling\n",
      "the\n",
      "eos\n",
      "with\n",
      "five\n",
      "fiducial\n",
      "densities\n",
      "between\n",
      "times\n",
      "the\n",
      "nuclear\n",
      "saturation\n",
      "density\n",
      "results\n",
      "in\n",
      "optimal\n",
      "errors\n",
      "for\n",
      "the\n",
      "smallest\n",
      "number\n",
      "of\n",
      "parameters\n",
      "specifically\n",
      "it\n",
      "the\n",
      "radii\n",
      "of\n",
      "the\n",
      "assumed\n",
      "eos\n",
      "to\n",
      "within\n",
      "less\n",
      "than\n",
      "km\n",
      "for\n",
      "the\n",
      "extreme\n",
      "mock\n",
      "equations\n",
      "of\n",
      "state\n",
      "and\n",
      "to\n",
      "within\n",
      "less\n",
      "than\n",
      "km\n",
      "for\n",
      "of\n",
      "a\n",
      "sample\n",
      "of\n",
      "proposed\n",
      "physically\n",
      "motivated\n",
      "equations\n",
      "of\n",
      "state\n",
      "such\n",
      "a\n",
      "parametrization\n",
      "is\n",
      "also\n",
      "able\n",
      "to\n",
      "reproduce\n",
      "the\n",
      "maximum\n",
      "mass\n",
      "to\n",
      "within\n",
      "m\n",
      "sun\n",
      "and\n",
      "the\n",
      "moment\n",
      "of\n",
      "inertia\n",
      "of\n",
      "a\n",
      "m\n",
      "sun\n",
      "neutron\n",
      "star\n",
      "to\n",
      "within\n",
      "less\n",
      "than\n",
      "for\n",
      "of\n",
      "the\n",
      "proposed\n",
      "sample\n",
      "of\n",
      "equations\n",
      "of\n",
      "state\n"
     ]
    }
   ],
   "source": [
    "jj = 14000\n",
    "for d in data[jj]:\n",
    "    print(word_index_reverse[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astro-ph.HE'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name[labels[jj]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8595854 , 0.06731834, 0.00543686, 0.01210889, 0.0184207 ,\n",
       "        0.03712979]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([data[jj]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astro-ph.HE'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name[labels[jj]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astro-ph.GA',\n",
       " 'astro-ph.SR',\n",
       " 'astro-ph.IM',\n",
       " 'astro-ph.EP',\n",
       " 'astro-ph.HE',\n",
       " 'astro-ph.CO']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15842, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15842,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.27219295501709, 0.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array([x_val[1000]]), np.array([y_val_one_hot[1000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2",
   "language": "python",
   "name": "tf-gpu-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
